---
title: "HW9_TestScores"
name: Hayden Whirley
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Did a New Reading Program Lead to Better Scores?

The superintendent recently claimed that a new reading program has improved third-grade reading scores across the school district.

Before the program, third-grade students in the district averaged 72.6 points on standardized reading tests with a standard deviation of 4.8 points.

After implementing the program for one semester, you collected scores from 12 randomly selected classrooms:
74, 76, 73, 75, 78, 77, 74, 79, 75, 76, 77, 75

As a journalist, you need to determine: **Is there statistical evidence that reading scores have actually improved?**

## Task 1: Organize your data and initial assessment

Before you can run this codeblock, you will need to fill in a value where it says REPLACE_ME. That value can be found in the introduction.

```{r}
# Known information about reading scores before the new program
prior_mean <- 72.6  # average score
prior_sd <- 4.8     # standard deviation

# Reading scores after implementing the new program (12 classrooms)
new_scores <- c(74, 76, 73, 75, 78, 77, 74, 79, 75, 76, 77, 75) # Replace with the actual scores

# Create a journalist-friendly dataset
score_data <- tibble(
  classroom = paste("Classroom", 1:12),
  reading_score = new_scores
)

# View the data
score_data
```

### Reflection Question 1:
Based on just looking at the score_data dataframe, have test scores improved? How can you tell?

Yes text scores have improved because they are all above the prior average of 72.6.

## Task 2: Calculate key statistics

Like Task 1, you will need to replace values where it says REPLACE_ME before running any code.


```{r}
# Calculate statistics based on the new reading scores
new_stats <- score_data |> 
  summarise(
    mean = mean(reading_score),
    sd = sd(reading_score),
    n = n()
  )

new_stats
```

### Reflection Question 2:
Looking at the mean and standard deviation of the new scores compared to the previous statistics, what initial observations can you make? What questions might these statistics raise for your reporting?

The mean increased by 3.15, and the standard deviation varies less, decreasing from 4.8 to 1.76, indicating that the new scores are more consistent and clustered closer to the mean. The increase in the mean suggests an overall improvement in scores. The decrease in standard deviation indicates that the scores are less spread out, so there is less variability among them. Some questions I would raise would be with a smaller standard deviation, are the new scores truly representative of all third-grade students in the district, or could the sample size and selection of classrooms have influenced the results? 

## Task 3: Create a column chart

As before, replace any values marked REPLACE_ME based the instructions.


```{r}
# STUDENT TASK: Choose an appropriate fill color for the bars
my_fill_color <- "royalblue" # Replace with a color name like "royalblue", "darkgreen", etc.

# Create a visualization comparing new scores to the previous average
score_data |> 
ggplot(aes(x = classroom, y = reading_score)) +
  geom_col(fill = my_fill_color, alpha = 0.8) +
  geom_hline(yintercept = prior_mean, color = "darkred", size = 1, linetype = "dashed") +
  annotate("text", x = 2, y = prior_mean - 1, 
           label = "Previous Average (72.6)", hjust = 0, fontface = "bold", color = "darkred") +
  labs(
    title = "Reading Scores After New Program Implementation",
    subtitle = "Horizontal line shows previous district average of 72.6 points",
    x = NULL,
    y = "Reading Test Score",
    caption = "Source: District Assessment Data"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Reflection Question 3:
Examine the chart you created, and suggest a better title based on the results of the data, not a description.

I think a better title would be "Third-grade reading scores after implementation of new reading program"

## Task 4: Perform a hypothesis test

This is where we formally test the superintendent's claim that reading scores have improved. Fill in the REPLACE_ME values as needed, beginning with your hypotheses.

**Hypotheses:**
Null: The new reading program has no effect on third-grade reading scores
Alternative: The new reading program has improved third-grade reading scores

```{r}
# Set the significance level for your test
alpha_level <- 0.05 # Replace with the appropriate value

# Perform a one-sample t-test
# Since we want to know if scores improved (increased), we use a one-sided test (alternative = "greater")
t_test_result <- t.test(
  score_data$reading_score,
  mu = prior_mean,
  alternative = "greater"
)

# Display the results
t_test_result
```

### Reflection Question 4:
What does the p-value tell you, and what doesn't it tell you? How would you explain these results to a non-technical audience while maintaining accuracy?

This p-value is extremely small, much smaller than the chosen significance level of 0.05. This means that there is strong statistical evidence that the new reading program has led to an improvement in test scores. We reject the null hypothesis and conclude that the program likely had a positive effect.
It doesn't tell me why the scores improved, whether the program will work for all students, or how much of a real-world impact the improvement has.
I would explain these results by saying that students' reading scores increased after the new program, and the chance of this happening randomly is very low, suggesting the program likely helped.

## Task 5: Interpreting the results for your news story

Let's gather all of the important stats we'll need in one place, so we can look at the prior average, the new scores and the results of the t.test, including the confidence interval. Replace any values where it says REPLACE_ME.


```{r}
# Get the p-value
p_value <- t_test_result$p.value

# Calculate the 95% confidence interval
ci <- t.test(score_data$reading_score)$conf.int

# Create a tibble to display the key statistics for your story
story_stats <- tibble(
  `Previous average` = prior_mean,
  `New average` = mean(score_data$reading_score),
  `Improvement` = mean(new_scores) - prior_mean,
  `Percent change` = round(((mean(new_scores) - prior_mean) / prior_mean) * 100, 1),
  `p-value` = p_value,
  `Lower bound` = ci[1],
  `Upper bound` = ci[2],
  `Confidence level` = "95%"
)

# Display the key statistics
story_stats
```

## Conclusion

### Reflection Question 5:
Based on these statistics, what would be your headline and lead paragraph for this story? Is there evidence to support the superintendent's claim?

"Study Shows New Reading Program Boosts Third-Grade Scores"

A new reading program implemented in the district has led to a statistically significant increase in third-grade reading scores, according to recent data. The average test score improved by 3.15 points, from 72.6 to 75.75, with the results showing a 4.3% increase. A t-test analysis showed a p-value of 3.43e-05, providing strong evidence that the program contributed to the improvement. The 95% confidence interval for the new scores ranges from 74.63 to 76.87, suggesting that the observed improvement is unlikely to have occurred by chance.

There is strong evidence to support the superintendent's claim largely due to the p-value. It is much smaller than the typical significance level of 0.05. This shows that the improvement is not due to random chance.


### Reflection Question 6:
What metrics or outcomes beyond test scores might be important to track for assessing reading performance?

I think some other important ways to track reading performance would be evaluating accuracy and fluency of words read in a certain amount of time (a minute) or through reading comprehension summaries or discussions. I think this could be more accurate than answering test questions because this requires students to actively engage with the material rather than just selecting an answer. Test scores may be inaccurate because students can guess, lack effort, run out of time etc.
